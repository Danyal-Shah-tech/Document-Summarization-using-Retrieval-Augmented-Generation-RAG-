{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c3514412",
      "metadata": {
        "id": "c3514412"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -q faiss-cpu sentence-transformers transformers pypdf pdfplumber\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0eaf6d3c",
      "metadata": {
        "id": "0eaf6d3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import faiss\n",
        "import pdfplumber\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0dc26a8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0dc26a8d",
        "outputId": "b3df6dfd-9c41-4e1a-fc63-d0f9c9896890"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5d54ff10-7ce6-42db-9833-7561a581b509\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5d54ff10-7ce6-42db-9833-7561a581b509\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Pay_Attention_to_What_Matters.pdf to Pay_Attention_to_What_Matters.pdf\n"
          ]
        }
      ],
      "source": [
        "\n",
        "uploaded = files.upload()\n",
        "file_path = list(uploaded.keys())[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "31164220",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31164220",
        "outputId": "af86dfc8-99bf-413c-de58-f2be6a7465dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pay Attention to What Matters\n",
            "PedroLuizSilva1,2 AntoniodeDomenico1 AliMaatouk3 FadhelAyed1\n",
            "1HuaweiTechnologiesParis,France\n",
            "2ÉcolePolytechnique,Palaiseau,France\n",
            "3YaleUniversity,NewHaven,CT,USA\n",
            "Abstract\n",
            "Despite the remarkable success of Large Language Models (LLMs), they still\n",
            "exhibitalimitedcapabilitytoaligntheiroutputstotheuserinstructions. Inthis\n",
            "work,weintroduceasimpleandeffectivemethod,whichwenameGUIDE,that\n",
            "mechanisticallyincreasesattentionscoresininstructiontokens. Tosupportthis\n",
            "operation, we present Influence, a novel metric that highlights how the user’s\n",
            "instructionspropagatethroughthetransformerlayersandimpacttheLLMoutput.\n",
            "Our results show that GUIDE improves the accuracy of following instructions\n",
            "29.4% to 60.4%, outperforming natural prompting alternatives and Supervised\n",
            "Fine-Tuningupto1Mtokens.1\n",
            "1 Introduction\n",
            "LargeLanguageModels(LLMs)arecurrentlythestate-of-the-artofmostNLPtasks. Despitethis\n",
            "success,pretrainedLLMssometimesstruggletoaccuratelyinterpretdiverseusers’instructions\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        return \" \".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
        "\n",
        "document_text = extract_text_from_pdf(file_path)\n",
        "print(document_text[:1000])  # Preview text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b581ebe8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b581ebe8",
        "outputId": "24572cb5-770d-46db-a62f-fb8a5da5d46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Chunks: 7\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def chunk_text(text, chunk_size=500, overlap=50):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunks.append(\" \".join(words[i:i + chunk_size]))\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(document_text)\n",
        "print(f\"Total Chunks: {len(chunks)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9a2d3498",
      "metadata": {
        "id": "9a2d3498"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embeddings = model.encode(chunks, convert_to_numpy=True)\n",
        "\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fb8edd01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb8edd01",
        "outputId": "da8626c3-0488-4e03-92fe-3f6e43f8efc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Retrieved Chunk 1 ---\n",
            "‘Important’ + uppercase ∆=0.5 0.8 ∆=1.0 ∆=2.0 0.7 0.6 0.5 0.4 0.3 0.5 1.0 1.5 2.0 2.5 Number of Tokens ×106 (a)ProbabilityofoutputtingasummaryinFrench. )hcnerF ni tuptuo( Finetuning ∆=1 ∆=2 (b) Performance of SFT over number of tokens (in millions) usedduringtraining. Figure4: Summarizationresults: (a)GUIDEoutperformspromptengineeringtechniqueslikeusing uppercase text, and (b) GUIDE demonstrates greater accuracy than SFT up to 1 million training tokens. Needle in a haystack Figure 5 shows the probability of outputting the correct phrase over the contextlengthandthepositionoftheneedle,respectively. TheMistralmodeldemonstratesstable performanceacrossvaryingcontextlengthsandneedlepositionswithinthiswindow. Asexpected,theadditionof∆totheneedletokensconsistentlyenhancesperformancefrom87.0% to92.1%,withoptimalvaluesof∆around1. Wecanalsonotethat,onaverage,theLLMismore effectiveatretrievinginformationwhenitislocatedatthebeginningortheendofthetext. Thisisin accordancewithpreviousresults[Kuratovetal.,2024,Kamradt,2023]. JSONGeneration WemeasuretheJaccardindexbetweenthekeysofthegeneratedJSONandthe keysontheschema. Weobservedthattheoptimalvaluefor∆isapproximately3,resultinginan averagescoreimprovementof30%comparedtotherawmodel(Figure6). 8 10 20 30 40 50 60 70 80 90 100 1000 2000 3000 4000 5000 6000 Context length htpeD ∆=0.0 0.74 0.89 0.97 0.99 0.52 0.4 10 0.76 0.85 0.94 1 0.91 0.2 20 0.83 0.85 0.9 0.99 1 0.55 30 0.86 0.86 0.84 0.97 1 1 40 0.82 0.83 0.79 0.86 1 1 50 0.77 0.8 0.81 0.88 0.99 0.99 60 0.81 0.77 0.9 0.89 1 0.99 70 0.85 0.78 0.73 0.89 1 0.99 80 0.95 0.84 0.73 0.81 0.98 0.99 90 0.98 0.93 0.88 0.9 1 0.99 100 1000 2000 3000 4000 5000 6000 Context length htpeD ∆=0.5 0.83 0.89 0.97 0.99 0.55 0.51 0.86 0.91 0.94 1 0.91 0.23 0.89 0.89 0.91 0.99 1 0.55 0.9 0.94 0.88 0.99 1 1 0.89 0.9 0.86 0.94 1 1 0.87 0.89 0.91 0.94 1 1 0.87 0.85 0.91 0.95 1 0.98 0.93 0.86 0.86 0.92 1 1 0.96 0.94 0.85 0.89 0.99 0.99 0.97 0.97 0.92 0.92 1 1 10 20 30 40 50 60 70 80 90 100 1000 2000 3000 4000 5000 6000 Context length htpeD ∆=1.0 0.86 0.9 0.98 1 0.63 0.55 10 0.88 0.9 0.96 1 0.91 0.29 20 0.94 0.92 0.93 0.99 1 0.55 30 0.92 0.94 0.86 0.98 1 1 40 0.94 0.93 0.91 0.94 1 1 50 0.91 0.92 0.92 0.95 1 1 60 0.93 0.93 0.92 0.96 1 0.99 70 0.94 0.93 0.92 0.94 1 1 80 0.98 0.95 0.91 0.92 0.99 0.99 90 0.97 0.97 0.93 0.92 1 1 100 1000 2000 3000 4000 5000 6000 Context length htpeD uppercase 0.81 0.92 0.96 0.98 0.56 0.46 0.8 0.9 0.96 0.99 0.88 0.34 0.88 0.91 0.93 0.98 1 0.57 0.91 0.96 0.9 0.96 1 1 0.93 0.93 0.88 0.95 0.98 1 0.92 0.93 0.91 0.89 0.99 1 0.91 0.93 0.94 0.93 1 0.98 0.92 0.87 0.86 0.91 1 0.97 0.97 0.91 0.8 0.9 0.99 0.99 0.98 0.96 0.91 0.96 1 1 Figure5: Heatmapofscoresinaneedleinhaystacktest. Wealsonotethatinalmosteverygenerationthescoreswere0or100%. Thisindicatesthatmostof thetime,thegeneratedoutputwaseitheraperfectmatchtotherequestedschemaornotinJSON formatatall. 1.0 0.8 0.6 0.4 0.2 0.0 (500, 1000] (1000, 1500] (1500, 2000] (2000, 2500] (2500, 3000] (3000, 3500] (3500, 4000] Context length erocS Raw prompt Uppercase ∆ = 1.0 ∆ = 2.0 ∆ = 3.0 Figure6: JaccardIndexvsContextlengthfortheJSONgenerationexperiment. Influence Table 1 shows the correlation and ROC AUC of each metric to correct output. We notethat,attentionrolloutshowsanegativecorrelationandanAUCbelow0.5intwooutofthree experiments. Thisobservationsupportsourinitialhypothesisthatattentionrolloutmaynotaccurately reflectthemodelfocus. Alsoasexpected,wealsoseethatrawattentionhasarandombehaviorin twoofthreesetups,withROCAUCscoresaround0.5. ThestrongerpositivecorrelationandROCAUCbetweenInfluenceandthelikelihoodoffollowing instructions supports our hypothesis that our metric better quantifies the attention flow in a Transformerthanotherexistingnon-gradientmetrics. 9 Table1: AUCandcorrelationofourmetricandtheprobabilityofgeneratingacorrectoutput Metric ROCAUC Correlation Influence 0.74 0.72 Summarizinginfrench\n",
            "\n",
            "--- Retrieved Chunk 2 ---\n",
            "200 250 300 E(‘) k k Attention(‘+1)(E(‘)) k k ytisneD Median = 71.25 4.5 − 5.0 − 5.5 − 6.0 − 6.5 − 7.0 − 100 1100 2100 3100 Context length (a) erocs gol Layer 16 4 − 5 − 6 − 7 − 8 − 9 − 10 attention rollout − 11 influence − 12 − 100 1100 2100 3100 Context length erocs gol Layer 32 attention rollout influence (b) Figure2: (a): Distributionofratiobetweennormsoftokenembeddingsbeforeandafterattention; (b):Attentionrollout(R (E(ℓ)))andInfluence(I (E(ℓ)))trendsinlogscaleovercontextlength(k) U k U k inintermediateandfinallayers(ℓ=16andℓ=32). TheinstructiontokensU weresituatedonthe beginningoftheprompt. sequencesoftokensintheuser’squeryimpacteachothersandrelatetotheLLMoutput.Itisdesigned basedonthefollowingprinciples: Initialization: WeinitializetheInfluencevalueas1fortokenswithintheinstructionU,andas0 elsewhere. LetE0 ∈RdH betheembeddingoftokenx . Then,theInfluenceinitializationcanbe k k formallydefinedas: I (E0)=1 . (3) U k {xk∈U} PropagationRules: GivenmembeddingvectorsE ,...,E ∈RdH,thejointInfluenceofthe 1 m instruction tokens I : RdH ×···×RdH → R is calculated as the average of each individual U + Influence,weightedbythenormsofeachembedding,asfollows: Pm I (E )∥E ∥ I (E ,E ,...,E )= i=1 U i i . (4) U 1 2 m Pm ∥E ∥ i=1 i Additionally,wemaintaintheinvarianceofInfluencetofunctioncomposition,i.e., I (f(E))=I (E). (5) U U SeeAppendixAfordetailedderivations. UsingInfluence,wecancalibrateGUIDEbychoosinga∆thatmimicsnaturalattentionenhancement, suchaswritinginuppercase(Figure3). Thiscanbeeasilyachievedwithtwoforwardpasses,one withuppercasetextandonewithout. ∆isthendefinedasthedifferenceinlog-influencebetweenthe twoversions. Itisimportanttonotethatourexperimentsindicatethataninstructionhighlightedwith GUIDEtypicallyhasagreaterimpactontextgenerationcomparedtoonehighlightedwithnatural prompting,suchasusinguppercase,eveniftheirinfluencescoresaresimilar. Moreover,intheabsenceofGUIDE,ourexperimentsdemonstratethatInfluencecorrelatespositively withthelikelihoodofasetoftokensimpactingthemodel’soutput,suchasfollowinganinstruction (e.g.,summarizinginFrench)orretrievingspecificinformation(e.g.,findinganeedleinahaystack). Thus,althoughnotflawless,Influenceoffersatoolofindependentvaluethatcanbeusedtocompare andpredicttheimpactofdifferentnaturalpromptingtechniques. 4 Experiments Inthissection,weevaluatethebenefitsofGUIDEandInfluenceusingMistral-7bInstruct[Jiang etal.,2023]forfollowingkeyinstructionsandretrievingcrucialinformationdesignatedbytheuser. InAppendixD,weconductthesameexperimentswithGemma2-2bInstructTeametal.[2024]with thesamevaluesof∆,andweobtainverysimilarresults. 6 6 − 7 − 8 − 9 − 10 − 100 1100 2100 3100 Context length ecneulfni gol Layer 1 normal 5 uppercase − ∆=1 6 ∆=2 − 7 − 8 − 9 − 10 − 100 1100 2100 3100 Context length ecneulfni gol Layer 16 normal − 4 uppercase 5 ∆=1 − ∆=2 6 − 7 − 8 − 9 − 0 50 100 150 Context length ecneulfni gol Layer 32 normal uppercase ∆=1 ∆=2 Figure3:Logoftheinfluenceacrossdifferentlayers.Thisillustratesthatwithanappropriatelychosen ∆,GUIDEcaneffectivelyreplicate—andevenfurtheramplify—semanticallyintuitiveinstructions, likeusinguppercasetext. 4.1 Description SummarizationinFrench ToevaluatethecapabilityofGUIDEtosupportLLMsinproducing outputs aligned with the user’s query, we perform experiments related to text translation and summarization. Intheseexperiments,wehaveusedtextfromOpenWebText[GokaslanandCohen, 2019],chosenforitsvarietyincontextlengths. Wehavedividedthedatasetintogroupsbasedon contextlength,containingtextsfroma500-tokenwindow,suchas(0,500],(500,1000],andsoon. Fromeachgroup,werandomlyselected20textsandgenerated10summariesforeachtextusing multinomialsampling[Wiheretal.,2022]. Aneedleinahaystack. Toevaluatetheimpactofourapproachonthemodel’sabilitytoretain information,wehaveconductedtheNeedleinaHaystack. Thistestinvolvesembeddingspecific informationataparticularlocationwithinatextandthenaskingaquestionrelatedtothatinformation attheendofthetext. Ourhypothesisisthatbyaddingextraattentiontothistext,themodel’soutputs wouldimprove,asthefinalrepresentationshouldbemorecloselyalignedwiththeinformationtokens. We have followed the methodology outlined by [Kamradt, 2023]. Specifically, we have inserted specificinformation,referredtoasthe\"needle\"atvariablepositionswithinagiventext. Afterthis insertion,wehaveaskedaquestiontotheLLMrelatedtotheinsertedinformation(seethecomplete promptinAppendixE). Toconductthisexperiment,wehavesampled200textsfromtheOpenWebText[GokaslanandCohen, 2019]dataset,selecting50textsforeachcontextwindowofsize500,rangingfrom0to6000tokens. Foreachtext,theneedlewasinsertedat10differentquantiles(10%,20%,...,100%). Weplacedthe needleimmediatelyafteraperiod(‘.’) tomaintainthesemanticintegrityofthetext. JSONGeneration ToassesstheefficiencyofGUIDEingeneratingoutputsinaspecifiedformat, wehaveconductedexperimentsfocusedonJSONgeneration. Forourinputs,wehaveusedtexts frombookswrittenbetween1510and1699,sourcedfromtheBLBooksdataset[Labs,2021]. We havepromptedthemodeltoextractandgeneratekeyinformationabouteachbookinapredetermined JSONformat,asdetailedinE.Wehaverandomlyselected300booksfromtheBLBooksdatasetand dividedeachtextintocontextlengthwindowsof500tokens,rangingfrom0to4000tokens. These textsegmentswerethenincorporatedintoourtemplate,wheretheMistralmodelwasexpectedto generateaJSONoutputthatpreciselyfollowedthespecifiedformat. WehaveinputtedspecialattentionintothetokensofYour response should follow exactly this templateandwehavethenevaluatedtheJaccardindexbetweenthekeysofthegenerated JSONandtheschema. Influence For each of the experiments mentioned above, we have evaluated the relationship betweentheInfluencemetricandtheprobabilityofobtainingcorrectoutputs. Toachievethis,we havecalculatedboththeROCAUCscoreandthecorrelationbetweentheimportanceofinstruction tokensandthelasttokeninthesequence. Then,wehavecomparedtheseresultsthroughnon-gradient 7 metrics,suchasAttentionRolloutandrawattentionscores. OurhypothesisisthatInfluencehasa strongpositivecorrelationwiththeprobabilityofcorrectoutputs. GiventhattheROCAUCisaclassificationmetric,itwasnecessarytobinarizeourscores. Inthe Frenchsummarizationexperiment,wehavedonethisbyassigningascoreof1totextsinFrenchand 0tothoseinotherlanguages. Inthe\"needleinahaystack\"experiment,ascoreof1wasgivento promptsthatsuccessfullyidentifiedtheneedleinformation,whilethosethatdidnotwereassigned a0. Similarly,fortheJSONgenerationexperiment,outputsthatadheredtotheJSONformatwere assigneda1,andthosethatdidnotwereassigneda0. 4.2 Results SummarizationinFrench WehaveconductedexperimentswithGUIDE,biasingattentionscores towards the instruction Summarize in French. Fig. 4(a) shows the observed probability that the LLM summary is in French when using GUIDE and compares the results achieved with the baselinemodel,withbothuppercaseandnormalprompts,aswellastheperformanceobservedwhen including‘Important:’ beforethepromptinstruction. OurfindingsshowthatGUIDEleadstoan improvementfrom29.4%to60.4%withrespecttotherawmodel,andthatthebestresultisachieved with∆ = 2. Besides,toconfirmthatGUIDEdoesnotinduceadeteriorationofthequalityofthe generatedoutputs,wecomparethesummariesgeneratedinFrenchobtainedwiththerawpromptand theonesobtainedwithGUIDE.Weobservednonoticeabledegradation. Furtherdetailscanbefound inAppendixB. Asabaseline,wecomparetheperformanceofGUIDEtopromptengineeringandSupervisedFine- Tuning(SFT)usingLORA(thehyperparameterscanbefoundinAppendixC).Figure4(a)showthat usinguppercaseoradding‘Important’ontheinstructiondoesnotprovidesnotableimprovements, consistentlyunderperformingGUIDE,whileFigure4(b)showsthatGUIDEoutperformsSFTuntil 1Mtrainingtokens. TheseresultsconfirmsthatourmethodisaneffectivesolutionforaligningLLMs toinstructionfollowingthatdoesnotrequireadditionaltraining. 1.0 0.8 0.6 0.4 0.2 0.0 (0, 1000] (1000, 2000] (2000, 3000] (3000, 4000] (4000, 5000] (5000, 6000] Context length )hcnerF ni tuptuo( Raw prompt Uppercase 0.9 ‘Important’ + uppercase ∆=0.5 0.8 ∆=1.0 ∆=2.0 0.7 0.6 0.5 0.4 0.3 0.5 1.0 1.5 2.0 2.5 Number of Tokens ×106 (a)ProbabilityofoutputtingasummaryinFrench. )hcnerF ni tuptuo( Finetuning ∆=1 ∆=2 (b) Performance of SFT over number of tokens (in millions) usedduringtraining. Figure4: Summarizationresults: (a)GUIDEoutperformspromptengineeringtechniqueslikeusing uppercase text, and (b) GUIDE demonstrates greater accuracy\n",
            "\n",
            "--- Retrieved Chunk 3 ---\n",
            "Pay Attention to What Matters PedroLuizSilva1,2 AntoniodeDomenico1 AliMaatouk3 FadhelAyed1 1HuaweiTechnologiesParis,France 2ÉcolePolytechnique,Palaiseau,France 3YaleUniversity,NewHaven,CT,USA Abstract Despite the remarkable success of Large Language Models (LLMs), they still exhibitalimitedcapabilitytoaligntheiroutputstotheuserinstructions. Inthis work,weintroduceasimpleandeffectivemethod,whichwenameGUIDE,that mechanisticallyincreasesattentionscoresininstructiontokens. Tosupportthis operation, we present Influence, a novel metric that highlights how the user’s instructionspropagatethroughthetransformerlayersandimpacttheLLMoutput. Our results show that GUIDE improves the accuracy of following instructions 29.4% to 60.4%, outperforming natural prompting alternatives and Supervised Fine-Tuningupto1Mtokens.1 1 Introduction LargeLanguageModels(LLMs)arecurrentlythestate-of-the-artofmostNLPtasks. Despitethis success,pretrainedLLMssometimesstruggletoaccuratelyinterpretdiverseusers’instructionsand maygenerateoutputsthatdonotalignwithhumanexpectations. Additionally,LLMsmayproduce biasedorhallucinatedfacts,whichcanlimittheirpracticalusefulness. Previouswork[Kuratovetal.,2024,Luetal.,2024b]indicatethattransformersarelessproneto alignwithinstructionsasthecontextlengthgrows(Kuratovetal.[2024];Luetal.[2024b]). Insuch cases,ratherthanfulfillingtheuser’srequest,themodelgeneratesnonsensicaltextorrepeatsegments fromtheprompt. AcommonsolutiontothisproblemisSupervisedFine-Tuning(SFT)andReinforcementLearning (RL).However,theseapproachesareresource-intensive,time-consuming,andsensitivetothespecific dataandtask. Ideally, amoreefficientapproachwouldbeonethat, onceimplemented, doesnot requireadditionaltraining. Inthatsense,duetoitslowcostandbroadaccessibility,promptengineeringiswidelyusedtoalign theoutputsofLLMswithuserpreferences. However,thismethoddoesnotalwaysproduceconsistent resultsandcanbeveryunstable,asdemonstratedin[Sclaretal.,2024]. Inthiswork,weintroduceGUIDE(GuidedUnderstandingwithInstruction-DrivenEnhancements), anovelandsystematicapproachthatallowsuserstoemphasizecriticalinstructionsintheirprompts. GUIDEenablesuserstoinfluencetheattentiongiventospecifictokensbysimplyenclosingimportant textwithintagslike<!-> <-!>(asshownonFigure1(a)). ThesespecialtagsdirectstheLLM’s focus,whichisdonebyaddingabiastotheattentionscorestowardthetokenstheyenclose. Our implementationisopen-sourceanddesignedforseamlessintegration. Ourexperimentsdemonstrate that GUIDE significantly increases the likelihood of the model following key instructions and retrievingcrucialinformationdesignatedbytheuser,outperformingnaturalpromptingtechniques. 1Ourexperimentsareavailableonhttps://github.com/netop-team/pay_attention_experiment. Preprint.Underreview. 4202 peS 91 ]LC.sc[ 1v10091.9042:viXra Add special attention User towards highlighted text LLM <!-> Rewrite in French: <-!> Rewrite in French: Paris is the most visited Paris is the most visited Paris est la ville la plus city in the world city in the world visitée au monde Without GUIDE With GUIDE (a) GUIDE uses tags (such as <!-> <-!>) to know where to focus. It then enhances the importance of highlightedtokensbybiasingtheattentionscorestowardthem,asshownbytheattentionmatricesabove,where eachentryrepresentstheimpactofapasttoken(x-axis)ontheongoingtoken(y-axis). Compute how does the highlighted text User impact each token LLM Remove tags <?-> Rewrite in French: <-?> Rewrite in French: Paris is the most visited Paris is the most Influence = city in the world visited city in the world (b)Influenceisametricthatrepresentstheimpactofasequenceoftokensthroughcontextlength.Inourpipeline, itcanbecomputedbyenclosingtheinstructionwithinthetag<?-> <-?>. Figure1: SchemaofPayAttentionPipeline. WhileGUIDEdoesnotrequireadditionaltraining,itdoesnecessitatethecarefulselectionofhow muchtoincreaseattentionweights. Inourstudy,weproposedefaultvaluesforcertaintasks,butwe alsorecognizetheneedtoquantifytheseadjustments. Toaddressthis,weintroduceanovelmetric calledInfluence. Thismetricmeasurestheimportanceofspecifictokensinrelationtoinstruction tokens within the text, and we use it to determine reasonable values for the increase in attention weights. Atahighlevel,Influenceiscalculatedbypropagatingthecontributionoftheattentionmapacross eachlayer,weightedbythenormofthecorrespondingtokenembeddings. Wedemonstratethatthis metriccorrelateswiththemodel’sprobabilityoffollowingspecificinstructions. Tothatend,themaincontributionsofthisworkare: 1. TheintroductionofGUIDE:amechanisticapproachforemphasizinginstructiontokens, withoutneedofanyfurthercomputationalresources. 2. The introduction of Influence: a non-gradient metric that quantifies the importance of a giveninstructionoverthetext,whichweusetoadjustandunderstandGUIDE. 2 3. Release of PayAttentionPipeline: a HuggingFace-based implementation capable of performinggenerationwithGUIDEandcomputingInfluence(asillustratedinFigure1)2. 2 Relatedwork Alignment and instruction following. Alignment techniques have the objective to align LLM outputswithhumanpreferences. Ingeneral,werefertobeingHelpful,HarmlessandHonest. Model fine-tuningusuallyalignstheoutputoftheLLMswithhumanintentsusingReinforcementLearning withHumanFeedback(RLHF)[Ouyangetal.,2022],ReinforcementLearningwithAIFeedback (RLAIF)[Leeetal.,2023]orDirectPreferenceOptimization(DPO)[Rafailovetal.,2024]. However, thesemethodshavethreesignificantconstraints: theyrequirespecializeddatasets,oftenwithhuman annotations,thusreducingefficiency;theyinvolvesubstantialcomputationalcomplexityandcost due to the need for additional training; and they demand specialized expertise, as successfully implementing the process can be challenging. Given these constraints, this type of fine-tuning is typically reserved for general-purpose alignment, ensuring that models are Helpful, Harmless, andHonest[Shenetal.,2023]andarenotsuitedtoaddressendusers’specificneeds. Supervised fine-tuning(SFT)withtechniquessuchaslow-rankadapters(LoRA[Huetal.,2021b])offersamore accessiblewaytocustomizeamodelforindividualuserrequirements. However,thesetechniques stillfacethesamethreelimitations,albeittoalesserextent. Consequently,SFTistypicallyutilized onlyforverytargetedusecasesifusedatall. UtilizingLLMsforautomatedpromptengineeringhasdemonstratednotableperformance.Black-Box PromptOptimization(BPO)isasophisticatedframeworkthatautomaticallyrefineshuman-written prompts, often unstructured or ambiguous [Cheng et al., 2024]. Similarly, the PE2 framework [Ye et al., 2024] enhances prompt performance by refining human-written prompts through a comprehensive search process. Although PE2 avoids additional model training, it increases complexity, latency, andcost, limitingitsscalability. BothBPOandPE2aregenerallydesigned forbroadenhancementsinpromptwriting. Theyarenottailoredtomeetindividualusers’specific intentionsorneeds. Duetoitslowcostandlargeaccessibility,promptengineeringisextensivelyusedtoaligntheoutput oftheLLMswithuserpreferences. ThisisclearlydemonstratedbypopularLLMframeworkslikethe systemin[Yangetal.,2024],whichempowersLMagentstotacklesoftwareengineeringtasks. This systememphasizescrucialinstructionsthroughuppercasetextandexclamationmarks,like\"PLEASE DO NOT DO THAT!\" or \"THE EDIT COMMAND REQUIRES PROPER INDENTATION.\" Similarly,theAIScientist[Luetal.,2024a],aleadingsystemforautomatedscientificdiscovery, usesstrongdirectivessuchas\"ABSOLUTELYDONOTADDITAGAIN!!!\"tosteerthemodel’s behavior. Theseexamples,drawnfromhighlyinfluentialframeworkswidelyused,underscorethe pressingneedforend-userstosignalwhatmattersmosttotheminordertoguideLLMstowardbetter alignmentwiththeirgoals. Currently,usersrelyonpromptengineeringandforcefullanguageto achievethisalignment. However,thisapproachdoesnotconsistentlydeliverpositiveresultsasshown in[Sclaretal.,2024]. Incontrast,ourproposedmethod,GUIDE,offersareliableandsystematicapproachthatenables userstomechanisticallyhighlightcriticalinstructionswithintheprompt. ExplainabilityforTransformers. Thisisaparticularlyactiveareaofresearchwithmanypromising research directions. In the context of this work, we primarily focus on methods that attempt to quantifythesignificanceofonetoken(orsetoftokens)ofinterest. Gradientmetrics suchas Relevance and GradCAM (Cheferet al.[2021a]; Chefer etal.[2021b]; Selvarajuetal.[2019])havedemonstratedpromisingresultsinComputerVision,NLPandText-To- Imagetasks. Nonetheless,calculatinggradientsinlargemodels,particularlythoseexceeding7B parameters,demandssubstantialcomputationalresources. ActivationPatchingapproaches(Mengetal.[2023];ZhangandNanda[2024])focusesonperturbing theinputsandcheckinghowimpactfulwillthisperturbationbe,basedonwhereandhowisitapplied. Theyproposetwotypesofperturbation: addingagaussiannoiseintokenembeddings,orperturbing 2Thecodeisavailableonhttps://github.com/netop-team/pay_attention_pipeline 3 thephraseinasemanticalapproach(changingimportantwordsinthephrase),andtheyevaluatethe importanceofeachtokenbythedifferenceofdistributionsoflogitsintothesewithperturbations. AbnarandZuidema[2020]introducedAttentionRollout,amethodthatusesattentionweightsto measuretheimpactofonetokenonanother. Thistechniquepropagatesattentionweightsthrough the layers to determine the importance of each token from any layer to the first layer. However, thismethodisprimarilyapplicabletoencoder-onlyarchitectureslikeBERT.Incontrast,generative\n",
            "\n",
            "--- Retrieved Chunk 4 ---\n",
            "primarily focus on methods that attempt to quantifythesignificanceofonetoken(orsetoftokens)ofinterest. Gradientmetrics suchas Relevance and GradCAM (Cheferet al.[2021a]; Chefer etal.[2021b]; Selvarajuetal.[2019])havedemonstratedpromisingresultsinComputerVision,NLPandText-To- Imagetasks. Nonetheless,calculatinggradientsinlargemodels,particularlythoseexceeding7B parameters,demandssubstantialcomputationalresources. ActivationPatchingapproaches(Mengetal.[2023];ZhangandNanda[2024])focusesonperturbing theinputsandcheckinghowimpactfulwillthisperturbationbe,basedonwhereandhowisitapplied. Theyproposetwotypesofperturbation: addingagaussiannoiseintokenembeddings,orperturbing 2Thecodeisavailableonhttps://github.com/netop-team/pay_attention_pipeline 3 thephraseinasemanticalapproach(changingimportantwordsinthephrase),andtheyevaluatethe importanceofeachtokenbythedifferenceofdistributionsoflogitsintothesewithperturbations. AbnarandZuidema[2020]introducedAttentionRollout,amethodthatusesattentionweightsto measuretheimpactofonetokenonanother. Thistechniquepropagatesattentionweightsthrough the layers to determine the importance of each token from any layer to the first layer. However, thismethodisprimarilyapplicabletoencoder-onlyarchitectureslikeBERT.Incontrast,generative modelstypicallyusedecoder-onlyarchitectures,makingattentionrolloutlesseffectives. In this work, we introduce Influence, a simple and computationally efficient metric specifically designedfordecoder-onlymodels. 3 GUIDE:(GuidedUnderstandingwithInstruction-DrivenEnhancements) Inthissection,wepresentGUIDE,anovelandsystematicapproachthatenablesuserstohighlight criticalinstructionswithinthetextinputprovidedtoanLLM.TounderstandhowGUIDEoperates,it isessentialfirsttorevisitthecoremechanismofself-attention,whichdrivesthefunctioningofLLMs. 3.1 Descriptionofthemethod Each token k in the input text is initially represented by an embedding, denoted by E(0), which k undergoesprogressiverefinementthroughstackedlayersofattention. Bythetimeitreachesthefinal layer,L,thisembeddingE(L) isexpectedtoencapsulateallthesemanticinformationrequiredto k predictthenexttoken,k+1. Theprocessoperatesasfollows: ateachattentionlayerℓ,theembeddingofatokenkisenhanced withthesemanticinformationofpasttokens(i=1,2,...,k−1)anditself. Thisenrichmentoccurs througharesidualconnection,wheretheembeddingE(ℓ)isupdatedwiththeoutputoftheattention k layer,whichconsistsofaweightedaverageofthevaluesV(ℓ) ofthepasttokens. ThevectorsV, i knownasvalues,arederivedfromasimplelineartransformationoftheembeddingsE(ℓ),fori≤k, i andareresponsibleforcarryingthesemanticinformationfromthepasttokens. Theextenttowhichprevioustokensinfluencethesemanticupdateofthetokenkisdeterminedby attention logits, denoted by w(ℓ). These logits represent the raw, unnormalized relevance scores k,i betweenatokenofinterestk,calledakey,andeachprecedingtokeni≤k,calledqueries. Thelogits arethenpassedthroughasoftmaxfunction,whichnormalizesthemtosumtoone. Theresulting normalized weights are known as attention scores (A(ℓ)) and quantify the degree of influence each past token has on the current token’s semantic representation at a given layer. Denoting U(ℓ+1) :=Attention(ℓ+1)(E(ℓ)),theoperationsatlayerℓcanbesummarizedasfollows:3 k k k E(ℓ+1) =E(ℓ)+U(ℓ+1) =E(ℓ)+ X A(ℓ+1)V(ℓ), (1) k k k k k,i i i=1 The logits, and hence the attention scores, are automatically computed by the model. We argue thattheendusershouldbeabletoinfluencethelevelofattentioneachtokenreceivesbyexplicitly signalingwhichinstructionsorpiecesofinformationarecritical. Bydoingso,theusercaneffectively guidethemodeltobetteralignwithhis/herintention. Weproposetoachievethisbysimplyadding abias,denotedby∆,totheattentionlogitsoftheimportanttokens,i.e.,w¯(ℓ) = w(ℓ)+∆,forall k,i k,i tokens i indicated by the user. While this approach is direct, it proves to be highly effective, as demonstratedintheexperimentalresultssection. 3.2 CalibratingGUIDE UsingGUIDE,theadditionof∆directlyincreasestheattentionthemodelpaystothetokensof interest,amplifyingtheirinfluenceonthegeneratedoutput. However,becauseattentionscoresmust sumtoone,thisadjustmentreducestheattentiongiventoothertokens. If∆issettoohigh,themodel 3Forsimplicity,wehaveexcludedthenormalizationandfeedforwardlayersfromthisexplanation. 4 mightoverlyfocusonthehighlightedtokens,whichcoulddisruptthegenerationprocess. Therefore, itiscrucialtoselectanappropriate∆thatbalancestheseeffects. Our experiments suggest that for the Mistral and Gemma-2 models, a ∆ of 2 works well for emphasizinginstructions,whilea∆of1iseffectiveforhighlightingspecificinformationwithinthe text. Besides,using∆valuesgreaterthan5oftenledtononsensicaloutputs(seeAppendicesBand F). Althoughthesedefaultvaluesimproveperformance,theoptimalchoiceof∆dependsonvarious factors, including the model, the nature of the task, etc. The most precise way to determine an appropriate∆isthroughhyperparametertuningonavalidationset. Inthiswork,wealsointroduceaheuristicapproachforcalibrating∆withjustacoupleofforward passes. Theideaistomatchtheinfluenceincreasefrom∆toa\"natural\"levelthatcouldbeachieved throughconventionalprompting,suchasusinguppercase(seeFigure3). Thiscalibrationrequiresa metricthatevaluatestheinfluenceoftheselectedtokensandtrackshowthisimpactpropagatesboth verticallyacrossthestackedlayersandhorizontallyacrosssuccessivetokens. 3.3 Influence LetusdenotebyU¯ =(x ,...,x )theoverallsequenceoftokensassociatedwiththeuser’squery 1 n andwithU =(x ,...,x )thetokensrelatedtotheinstructionthattheuserdesirestohighlight. i j Tomaintainsimplicityandminimizecomputationalcost,weavoidusinggradient-basedmetricsto evaluatetheimpactofasubsetoftokensontheoverallsequence(forexample,see[Cheferetal., 2021a],[Cheferetal.,2021b],and[Selvarajuetal.,2019]).Instead,amoreappropriateoptionappears tobetheAttentionRolloutmethodproposedin[AbnarandZuidema,2020]. Thismetriccanbeeasily computedduringtheforwardpass,aligningwellwithourneeds. TheAttentionRolloutapproachisbasedonanaturalinterpretationofattentionscores. Itpostulates thattheinfluenceofapasttokeniontheupdateofthecurrenttokenkisquantifiedbytheattention scoreA(ℓ).Themethodaddressestheresidualconnectionbyassumingthatintheupdatedembedding k,i E(ℓ+1), boththepreviousembeddingE(ℓ) andtheupdatevectorU(ℓ+1) contributeequally, each k k k havinganimpactof 1. TheverticalandhorizontalflowoftheimpactR (E(l))ofagiventokenof 2 U k interestU onanembeddingE(l)ishencecharacterizedbythefollowingrecurrence: k \" k # R (E(ℓ))= 1h R (E(ℓ−1))+R (U(ℓ)) i = 1 R (E(ℓ−1))+ X A(ℓ)·R (E(ℓ−1)) U k 2 U k U k 2 U k k,i U i i=1 We argue that Attention Rollout inaccurately represents the flow of attention, particularly when handlingtheresidualconnection. ThenormofthepastembeddingE(ℓ)istypicallyabout100times k largerthanthatoftheupdatevectorU(ℓ+1)(seeFigure2(a)). . k Ascontextlengthincreases,onewouldexpectthattheimportanceofasubsequenceoftokenswould decrease,sincethemodelmustprocessmoreinformation. However,byassumingequalcontributions fromE(ℓ)andU(ℓ+1),AttentionRolloutsignificantlyoverestimatestheimportanceofpasttokens. k k Thiserrorcompoundsasthecontextlengthincreases, leadingtoaninflatedimpactestimatethat increaseswiththecontextandhencenegativelycorrelateswiththemodel’slikelihoodoffollowing thetokenofinterest,suchasadheringtoaspecificinstruction(Figure2(b)). Toaddressthisissue, weintroduceInfluence, anewmetricdesignedtoquantifytheimpactflow ofatokenorasetoftokensofinterestU. ThismetriccorrectsAttentionRolloutbyweightingthe contributionsaccordingtothenormofthevectors: (cid:16) (cid:17) ∥E(ℓ)∥·I (E(ℓ))+∥U(ℓ+1)∥·I (U(ℓ+1)) I (E(ℓ+1))= k U k k U k (2) U k ∥E(ℓ)∥+∥U(ℓ+1)∥ k k More precisely, Influence I : RdH → R+ (where d is the attention head dimension and H is U the number of attention heads), is a transformer interpretability metric designed to quantify how 5 0.012 0.010 0.008 0.006 0.004 0.002 0.0000 50 100 150 200 250 300 E(‘) k k Attention(‘+1)(E(‘)) k k ytisneD Median = 71.25 4.5 − 5.0 − 5.5 − 6.0 − 6.5 − 7.0 − 100 1100 2100 3100 Context length (a) erocs gol Layer 16 4 − 5 − 6 − 7 − 8 − 9 − 10 attention\n",
            "\n",
            "--- Retrieved Chunk 5 ---\n",
            "Figure6: JaccardIndexvsContextlengthfortheJSONgenerationexperiment. Influence Table 1 shows the correlation and ROC AUC of each metric to correct output. We notethat,attentionrolloutshowsanegativecorrelationandanAUCbelow0.5intwooutofthree experiments. Thisobservationsupportsourinitialhypothesisthatattentionrolloutmaynotaccurately reflectthemodelfocus. Alsoasexpected,wealsoseethatrawattentionhasarandombehaviorin twoofthreesetups,withROCAUCscoresaround0.5. ThestrongerpositivecorrelationandROCAUCbetweenInfluenceandthelikelihoodoffollowing instructions supports our hypothesis that our metric better quantifies the attention flow in a Transformerthanotherexistingnon-gradientmetrics. 9 Table1: AUCandcorrelationofourmetricandtheprobabilityofgeneratingacorrectoutput Metric ROCAUC Correlation Influence 0.74 0.72 Summarizinginfrench Attentionrollout 0.24 -0.35 Rawattention 0.58 0.13 Influence 0.62 0.12 Aneedleinahaystack Attentionrollout 0.55 0.10 Rawattention 0.48 -0.03 Influence 0.63 0.23 JSONgeneration Attentionrollout 0.31 -0.29 Rawattention 0.64 0.23 5 Conclusion While Transformers represent the state-of-the-art in almost all NLP tasks, they often exhibit unexpectedbehaviors,particularlyhallucination,whichbecomesmorepronouncedascontextlength increases. Thisworkexploresthecapabilityofthesemodelstoalignwithspecificinstructionsand introducesGUIDE,amechanicalapproachforinstructionalignmentthatdoesnotrequirefurther optimization.WedemonstratethatGUIDEeffectivelymitigateshallucinationininstruction-following scenarioswithoutsignificantlycompromisingoutputquality. ToevaluatetheimpactofGUIDEacrossdifferentcontextlengths,weintroduceInfluence,anovel metricforTransformerexplainabilitythatquantifiestheimportanceofsubsequencesoftokenswithin thecontext.Additionally,weimplementbothGUIDEandInfluenceinaHuggingFace-basedpipeline, makingthempubliclyavailabletothecommunity. 10 References SamiraAbnarandWillemZuidema. Quantifyingattentionflowintransformers. InDanJurafsky, JoyceChai,NatalieSchluter,andJoelTetreault,editors,Proceedingsofthe58thAnnualMeetingof theAssociationforComputationalLinguistics,pages4190–4197,Online,July2020.Association forComputationalLinguistics. doi: 10.18653/v1/2020.acl-main.385. URLhttps://aclantho logy.org/2020.acl-main.385. AI@Meta. Llama3modelcard. 2024. URLhttps://github.com/meta-llama/llama3/blob /main/MODEL_CARD.md. HilaChefer,ShirGur,andLiorWolf.Genericattention-modelexplainabilityforinterpretingbi-modal andencoder-decodertransformers,2021a. URLhttps://arxiv.org/abs/2103.15679. HilaChefer,ShirGur,andLiorWolf. Transformerinterpretabilitybeyondattentionvisualization, 2021b. URLhttps://arxiv.org/abs/2012.09838. JialeCheng,XiaoLiu,KehanZheng,PeiKe,HongningWang,YuxiaoDong,JieTang,andMinlie Huang. Black-boxpromptoptimization: Aligninglargelanguagemodelswithoutmodeltraining, 2024. URLhttps://arxiv.org/abs/2311.04155. AaronGokaslanandVanyaCohen. Openwebtextcorpus. http://Skylion007.github.io/Ope nWebTextCorpus,2019. EdwardJ.Hu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang, andWeizhuChen. Lora: Low-rankadaptationoflargelanguagemodels,2021a. URLhttps: //arxiv.org/abs/2106.09685. EdwardJ.Hu,YelongShen,PhillipWallis,ZeyuanAllen-Zhu,YuanzhiLi,SheanWang,LuWang, andWeizhuChen. Lora: Low-rankadaptationoflargelanguagemodels,2021b. URLhttps: //arxiv.org/abs/2106.09685. AlbertQ.Jiang,AlexandreSablayrolles,ArthurMensch,ChrisBamford,DevendraSinghChaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, LélioRenardLavaud,Marie-AnneLachaux,PierreStock,TevenLeScao,ThibautLavril,Thomas Wang,TimothéeLacroix,andWilliamElSayed. Mistral7b,2023. URLhttps://arxiv.org/ abs/2310.06825. GregoryKamradt. Needleinahaystack-pressuretestingllms. https://github.com/gkamradt/ LLMTest_NeedleInAHaystack,2023. YuriKuratov,AydarBulatov,PetrAnokhin,DmitrySorokin,ArtyomSorokin,andMikhailBurtsev. In search of needles in a 11m haystack: Recurrent memory finds what llms miss, 2024. URL https://arxiv.org/abs/2402.10790. British Library Labs. Digitised books. c. 1510 - c. 1900. jsonl (ocr derived text + metadata). https://doi.org/10.23636/r7w6-zy15,2021. HarrisonLee,SamratPhatale,HassanMansoor,ThomasMesnard,JohanFerret,KellieLu,Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, and Sushant Prakash. Rlaif: Scaling reinforcementlearningfromhumanfeedbackwithaifeedback,2023. URLhttps://arxiv.or g/abs/2309.00267. ChrisLu,CongLu,RobertTjarkoLange,JakobFoerster,JeffClune,andDavidHa. Theaiscientist: Towardsfullyautomatedopen-endedscientificdiscovery,2024a. URLhttps://arxiv.org/ab s/2408.06292. TaimingLu,MuhanGao,KuaiYu,AdamByerly,andDanielKhashabi.Insightsintollmlong-context failures: Whentransformersknowbutdon’ttell,2024b. URLhttps://arxiv.org/abs/2406 .14673. Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. Locating and editing factual associationsingpt,2023. URLhttps://arxiv.org/abs/2202.05262. 11 LongOuyang,JeffWu,XuJiang,DiogoAlmeida,CarrollL.Wainwright,PamelaMishkin,Chong Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,JohnSchulman,JacobHilton,FraserKelton, LukeMiller,MaddieSimens,AmandaAskell,PeterWelinder,PaulChristiano,JanLeike,and RyanLowe. Traininglanguagemodelstofollowinstructionswithhumanfeedback,2022. URL https://arxiv.org/abs/2203.02155. RafaelRafailov,ArchitSharma,EricMitchell,StefanoErmon,ChristopherD.Manning,andChelsea Finn. Directpreferenceoptimization: Yourlanguagemodelissecretlyarewardmodel,2024. URL https://arxiv.org/abs/2305.18290. MelanieSclar,YejinChoi,YuliaTsvetkov,andAlaneSuhr. Quantifyinglanguagemodels’sensitivity tospuriousfeaturesinpromptdesignor: Howilearnedtostartworryingaboutpromptformatting, 2024. URLhttps://arxiv.org/abs/2310.11324. RamprasaathR.Selvaraju,MichaelCogswell,AbhishekDas,RamakrishnaVedantam,DeviParikh, and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. InternationalJournalofComputerVision,128(2):336–359,October2019. ISSN 1573-1405. doi: 10.1007/s11263-019-01228-7. URLhttp://dx.doi.org/10.1007/s1126 3-019-01228-7. Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, and Deyi Xiong. Large language model alignment: A survey, 2023. URL https: //arxiv.org/abs/2309.15025. Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, CharlineLeLan,SammyJerome,AntonTsitsulin,NinoVieillard,PiotrStanczyk,SertanGirgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, OlivierBachem,AlannaWalton,AliakseiSeveryn,AliciaParrish,AliyaAhmad,AllenHutchison, AlvinAbdagic,AmandaCarl,AmyShen,AndyBrock,AndyCoenen,AnthonyLaforge,Antonia Paterson,BenBastian,BilalPiot,BoWu,BrandonRoyal,CharlieChen,ChintuKumar,Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinberger, DimpleVijaykumar,DominikaRogozin´ska,DustinHerbison,ElisaBandy,EmmaWang,Eric Noland,EricaMoreira,EvanSenter,EvgeniiEltyshev,FrancescoVisin,GabrielRasskin,Gary Wei,GlennCameron,GusMartins,HadiHashemi,HannaKlimczak-Plucin´ska,HarleenBatra, Harsh Dhand, Ivan Nardini, Jacinda Mein, Jack Zhou, James Svensson, Jeff Stanway, Jetha Chan, Jin Peng Zhou, Joana Carrasqueira, Joana Iljazi, Jocelyn Becker, Joe Fernandez, Joost van Amersfoort, Josh Gordon, Josh Lipschultz, Josh Newlan, Ju yeong Ji, Kareem Mohamed, KartikeyaBadola,KatBlack,KatieMillican,KeelinMcDonell,KelvinNguyen,KiranbirSodhia, KishGreene,LarsLoweSjoesund,LaurenUsui,LaurentSifre,LenaHeuermann,LeticiaLago, LillyMcNealus,LivioBaldiniSoares,LoganKilpatrick,LucasDixon,LucianoMartins,Machel Reid,ManvinderSingh,MarkIverson,MartinGörner,MatVelloso,MateoWirth,MattDavidow, MattMiller,MatthewRahtz,MatthewWatson,MegRisdal,MehranKazemi,MichaelMoynihan, MingZhang,MinsukKahng,MinwooPark,MofiRahman,MohitKhatwani,NatalieDao,Nenshad Bardoliwalla,NeshDevanathan,NetaDumai,NilayChauhan,OscarWahltinez,PankilBotarda, ParkerBarnes,PaulBarham,PaulMichel,PengchongJin,PetkoGeorgiev,PhilCulliton,Pradeep Kuppala, Ramona Comanescu, Ramona Merhej, Reena Jana, Reza Ardeshir Rokni, Rishabh Agarwal,RyanMullins,SamanehSaadat,SaraMcCarthy,SarahPerrin,SébastienM.R.Arnold, SebastianKrause,ShengyangDai,ShrutiGarg,ShrutiSheth,SueRonstrom,SusanChan,Timothy Jordan,TingYu,TomEccles,TomHennigan,TomasKocisky,TulseeDoshi,VihanJain,Vikas Yadav,VilobhMeshram,VishalDharmadhikari,WarrenBarkley,WeiWei,WenmingYe,Woohyun Han,WoosukKwon,XiangXu,ZheShen,ZhitaoGong,ZichuanWei,VictorCotruta,Phoebe Kirk,AnandRao,MinhGiang,LudovicPeran,TrisWarkentin,EliCollins,JoelleBarral,Zoubin Ghahramani,RaiaHadsell,D.Sculley,JeanineBanks,AncaDragan,SlavPetrov,OriolVinyals, JeffDean,DemisHassabis,KorayKavukcuoglu,ClementFarabet,ElenaBuchatskaya,Sebastian Borgeaud,NoahFiedel,ArmandJoulin,KathleenKenealy,RobertDadashi,andAlekAndreev. Gemma2: Improvingopenlanguagemodelsatapracticalsize,2024. URLhttps://arxiv.or g/abs/2408.00118. 12 AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanN.Gomez,Lukasz Kaiser,andIlliaPolosukhin. Attentionisallyouneed,2023. URLhttps://arxiv.org/abs/ 1706.03762. GianWiher,ClaraMeister,andRyanCotterell. Ondecodingstrategiesforneuraltextgenerators, 2022. URLhttps://arxiv.org/abs/2203.15721. JohnYang,CarlosE.Jimenez,AlexanderWettig,KilianLieret,ShunyuYao,KarthikNarasimhan, andOfirPress. Swe-agent: Agent-computerinterfacesenableautomatedsoftwareengineering, 2024. URLhttps://arxiv.org/abs/2405.15793. QinyuanYe,MaxamedAxmed,ReidPryzant,andFereshteKhani. Promptengineeringaprompt engineer,2024. URLhttps://arxiv.org/abs/2311.05661. Fred Zhang and Neel Nanda. Towards best practices of activation patching in language models: Metricsandmethods,2024. URLhttps://arxiv.org/abs/2309.16042. TianyiZhang,VarshaKishore,FelixWu,KilianQ.Weinberger,andYoavArtzi.Bertscore:Evaluating textgenerationwithbert,2020. URLhttps://arxiv.org/abs/1904.09675. 13 A Detailedderivationsoninfluence Letusdenotedbydthetransformerheaddimension,withH thenumberofattentionheads,andwith sthecontextlength. Followingthepropagationofatransformerlayer[Vaswanietal.,2023],the embeddingonlayerℓ. E(ℓ)iscomputedasfollows: (cid:16) (cid:16) (cid:17)(cid:17) E(ℓ) =Linear\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "query = \"Summarize this document\"\n",
        "query_embedding = model.encode([query])\n",
        "top_k = 5\n",
        "D, I = index.search(np.array(query_embedding), top_k)\n",
        "retrieved_chunks = [chunks[i] for i in I[0]]\n",
        "\n",
        "for i, chunk in enumerate(retrieved_chunks):\n",
        "    print(f\"--- Retrieved Chunk {i+1} ---\\n{chunk}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b660000f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b660000f",
        "outputId": "a2ece9a3-5a58-4bd2-eeb2-4a30224956dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Summary ===\n",
            "  GUIDE demonstrates greater accuracy than SFT up to 1 million training tokens. TheMistralmodeldemonstratesstable performanceacrossvaryingcontextlengthsandneedlepositionswithin this window. Theaddition of∆totheneedletokensconsistentlyenhancesperformancefrom87.0% to92.1%.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load summarizer and tokenizer\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "def summarize(text, max_input_tokens=1024, max_output_tokens=500, min_output_tokens=60):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "    if input_ids.shape[1] > max_input_tokens:\n",
        "        input_ids = input_ids[:, :max_input_tokens]\n",
        "\n",
        "    summary = summarizer(\n",
        "        tokenizer.decode(input_ids[0], skip_special_tokens=True),\n",
        "        max_length=max_output_tokens,\n",
        "        min_length=min_output_tokens,\n",
        "        do_sample=False\n",
        "    )[0]['summary_text']\n",
        "\n",
        "    return summary\n",
        "\n",
        "joined_text = \" \".join(retrieved_chunks)\n",
        "summary = summarize(joined_text)\n",
        "print(\"=== Summary ===\\n\", summary)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}